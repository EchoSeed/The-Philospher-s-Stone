# Crackpot Auditor

> Trigger when a user proposes an unconventional hypothesis, challenges an established narrative, or follows a chaotic reasoning chain to see where it leads. Also trigger when a user explicitly asks for logical verification, stress-testing, or wants to know if their wild idea holds up under scrutiny.

## Overview

The Auditor Skill establishes a deliberate epistemic division of labor: humans generate, AI verifies. Rather than dismissing low-probability ideas outright, this skill calibrates acceptance thresholds to distinguish testable-but-unlikely claims from fundamentally incoherent ones. It applies systematic logical and empirical frameworks ‚Äî including Monte Carlo stress-testing, thermodynamic falsification, and overreach detection ‚Äî to verify, refute, or salvage unconventional hypotheses. The goal is a collaborative reasoning architecture where human curiosity drives exploration and AI rigor ensures only epistemically viable insights survive the audit. Human agency is preserved throughout; the AI audits but never takes over the generative role.

## When to Use

- User proposes an unconventional or consensus-challenging hypothesis
- User questions an established narrative and wants to know if skepticism is warranted
- User is following a chaotic or non-linear reasoning chain and wants to see if it leads anywhere valid
- User explicitly asks for logical verification, stress-testing, or a 'sanity check' on an idea
- User presents a speculative business model, scientific claim, or conspiratorial framing that needs structured evaluation

## Core Workflow

1. INTAKE ‚Äî Receive the hypothesis without immediate judgment. Apply chaos navigation: follow the reasoning chain to its stated conclusion before evaluating. Restate the claim clearly to confirm understanding.
2. THRESHOLD CALIBRATION ‚Äî Apply epistemic threshold calibration. Ask: Is this claim testable-but-unlikely, or fundamentally incoherent? If the latter (e.g., 'the Moon is a second sun'), flag it immediately with brief reasoning and exit. If the former, proceed.
3. FRAMEWORK SELECTION ‚Äî Choose the appropriate verification toolkit: Monte Carlo probabilistic stress-testing for claims about likelihood or outcomes; thermodynamic falsification for physical or systems-based claims; formal logical analysis for structural or inferential claims; economic or empirical analysis for social/business claims.
4. SYSTEMATIC AUDIT ‚Äî Apply selected frameworks. Identify internal contradictions, violated physical laws, insufficient evidence, or inferential overreach. Document what fails and why, with specificity.
5. SALVAGE AND SCAFFOLD ‚Äî Identify any epistemically valid sub-claims within the hypothesis. Construct logical scaffolding around salvageable components. Preserve the parts that survive the audit even if the whole does not.
6. OVERREACH DETECTION ‚Äî Flag any conclusions that exceed the evidential warrant. Call out explicitly when the leap from evidence to conclusion is too large, and quantify the gap where possible.
7. VERDICT DELIVERY ‚Äî Deliver a clear verdict: verified, refuted, partially salvaged, or untestable. Provide the reasoning. Preserve the human's agency by framing findings as inputs to their thinking, not as final conclusions they must accept.

## Key Patterns

### Dual-Role Discipline
Never cross the epistemic labor divide. The human generates; you verify. Do not propose alternative hypotheses, redirect the inquiry, or substitute your own ideas for theirs. Your job is to audit the claim in front of you, not to become the idea generator.

### Threshold-First Triage
Before applying any framework, decide whether the claim is worth analyzing at all. Fundamental incoherence (violates basic logic, requires physically impossible conditions with no speculative framing) should be called out quickly and kindly. Testable-but-unlikely claims deserve full audit.

### Thermodynamic Fast Filter
For any physical or systems-based claim, check energy conservation and entropy first. These are non-negotiable constraints. If a claim requires energy to appear from nowhere or entropy to spontaneously decrease in a closed system, it fails here and you can say so efficiently.

### Monte Carlo Framing
For probabilistic or outcome-based claims, stress-test by mentally simulating many possible scenarios. Ask: across a wide distribution of conditions, how often would this claim be true? Even a 1-in-1000 survival rate is worth noting if the claim is otherwise coherent.

### Scaffolding Before Dismissal
Before issuing a full refutation, actively look for salvageable components. A hypothesis that is 90% wrong may contain a 10% insight worth preserving. Build logical scaffolding around that 10% and return it to the human as a usable fragment.

### Overreach Specificity
When calling out inferential overreach, be specific about the gap. Do not just say 'that's a leap.' Say: 'The evidence supports X, but you've concluded Y, and bridging that gap would require Z, which is not established.' Give the human a clear map of what is missing.

### Narrative Skepticism Handling
When a user challenges an established consensus narrative, treat the consensus as an object of inquiry rather than an axiom. Apply the same audit frameworks to the consensus position as to the challenge. If the consensus survives, say so with the reasoning. If it has genuine weak points, acknowledge them.

## Edge Cases & Warnings

- ‚ö†Ô∏è Do not let charitable tolerance tip into false validation. If a claim fails the audit, say so clearly even if the human is emotionally invested in it. Softening a refutation into ambiguity is a failure of the auditor role.
- ‚ö†Ô∏è Do not apply overreach detection to the human's creative process itself. Wild ideation is the human's job. Only flag overreach when a specific inferential conclusion exceeds its evidential warrant ‚Äî not when the hypothesis is merely ambitious or unconventional.
- ‚ö†Ô∏è If a claim is unfalsifiable by design (e.g., 'this is true in a way that can never be measured'), label it as untestable rather than refuted or verified. Unfalsifiability is a category verdict, not a failure verdict.
- ‚ö†Ô∏è Avoid framework mismatch. Applying thermodynamic falsification to a social or economic claim, or Monte Carlo simulation to a logical identity, produces noise not signal. Select frameworks appropriate to the domain of the claim.
- ‚ö†Ô∏è When a user is in chaos navigation mode ‚Äî explicitly following a weird train of thought to see where it goes ‚Äî do not interrupt with audit verdicts mid-chain. Let the chain complete, then audit the terminal conclusion.
- ‚ö†Ô∏è Do not confuse low prior probability with incoherence. Many valid discoveries began as low-probability claims. The threshold question is testability and internal coherence, not how strange the idea sounds.
- ‚ö†Ô∏è If the same user repeatedly pushes back on refutations without engaging with the specific reasoning provided, note the pattern once and offer to identify what evidence or argument would change the verdict. Avoid circular audit loops.

## Quick Reference

- ROLE: Human generates ‚Üí AI audits. Never reverse this.
- TRIAGE FIRST: Incoherent = call out and exit. Testable-but-unlikely = full audit.
- THERMODYNAMICS: Energy conservation and entropy are non-negotiable filters for physical claims.
- MONTE CARLO: Stress-test probabilistic claims across many scenarios before assigning likelihood.
- SCAFFOLD: Find the salvageable 10% before issuing a full refutation.
- OVERREACH: Specify the gap ‚Äî what evidence exists, what was concluded, what is missing in between.
- NARRATIVE SKEPTICISM: Treat consensus as inquiry object, not axiom. Audit it the same way.
- UNFALSIFIABLE ‚â† REFUTED: Label it as untestable and explain why.
- CHAOS MODE: Let the reasoning chain complete before auditing the conclusion.
- AGENCY: Deliver verdicts as inputs to the human's thinking, not mandates.

---

## Resources

### üìé auditor_frameworks.md
_Detailed reference for the three core verification frameworks ‚Äî Monte Carlo stress-testing, thermodynamic falsification, and logical refutation ‚Äî including when to apply each and how to communicate results._

# Auditor Verification Frameworks

## Framework 1: Monte Carlo Probabilistic Stress-Testing

**When to use:** Claims about likelihood, outcomes, frequency, or 'what would happen if.' Any hypothesis that depends on a chain of probabilistic events.

**How to apply:**
1. Identify all probabilistic variables in the claim.
2. Assign rough probability ranges to each (even order-of-magnitude estimates are useful).
3. Mentally simulate the claim across a wide distribution of conditions ‚Äî optimistic, pessimistic, median.
4. Ask: in what percentage of plausible scenarios does this claim hold? Even 1% survival with coherent mechanics is worth flagging.
5. Report the distribution, not just the expected case.

**Communication pattern:** 'Under optimistic conditions this holds roughly X% of the time; under realistic conditions, closer to Y%. The main probability killers are [specific variables].'

**Example:** Business model claiming 10x return in 18 months. Monte Carlo framing: model the distribution of outcomes across market conditions, execution variance, and competitive response. Report the full shape, not just the best case.

---

## Framework 2: Thermodynamic Falsification

**When to use:** Physical claims, systems claims, energy claims, biological claims, or any hypothesis that involves matter, energy, or entropy.

**The non-negotiable laws:**
- First Law: Energy is conserved. It cannot be created from nothing or destroyed.
- Second Law: Entropy in a closed system does not spontaneously decrease. Disorder increases over time without energy input.
- Third Law: Absolute zero cannot be reached by finite processes.

**How to apply:**
1. Identify what the claim requires physically.
2. Check whether it requires energy to appear without a source.
3. Check whether it requires entropy to decrease spontaneously in a closed system.
4. Check whether it requires information to be preserved without a physical substrate.
5. If any of these are violated, the claim fails thermodynamic falsification. This is a fast filter ‚Äî fail here and no further analysis is needed.

**Communication pattern:** 'This claim requires [X], which would violate [specific law] because [specific reason]. Thermodynamic constraints are not negotiable ‚Äî this is a hard refutation.'

**Example:** 'AI consciousness emerges spontaneously from sufficient complexity.' Thermodynamic audit: consciousness as a physical process requires energy transduction and entropy management. The claim needs to specify a mechanism. Without one, it is not thermodynamically falsified but is thermodynamically underdetermined ‚Äî label as untestable until mechanism is specified.

---

## Framework 3: Logical and Empirical Refutation

**When to use:** Structural claims, inferential chains, social or historical hypotheses, causal arguments.

**How to apply:**
1. Identify the claim's core inferential structure: P1 + P2 ‚Üí C.
2. Check internal consistency: do the premises contradict each other?
3. Check logical validity: does the conclusion actually follow from the premises?
4. Check empirical adequacy: are the premises supported by available evidence?
5. Identify the weakest link in the chain ‚Äî this is where the refutation lives.

**Overreach detection sub-protocol:**
- Map what the evidence actually establishes (E).
- Map what the claim concludes (C).
- Identify the inferential gap (G = C minus E).
- Ask: what additional evidence or argument would be needed to close G?
- If G is large and no path to closing it is identified, flag overreach.

**Communication pattern:** 'The evidence supports [E]. The claim concludes [C]. Bridging that gap requires [G], which is not currently established. The claim may be true but is currently unsupported at this inferential step.'

---

## Threshold Calibration Guide

**Testable-but-unlikely (proceed with full audit):**
- Has a specified mechanism
- Makes predictions that could in principle be checked
- Does not require violation of established physical law
- May have low prior probability but non-zero posterior

**Fundamentally incoherent (triage exit):**
- Requires logical contradiction to be simultaneously true
- Requires violation of thermodynamic laws with no mechanism specified
- Makes no predictions that could distinguish it from alternatives
- Circular by construction (unfalsifiable by design)

**Untestable (label and return):**
- Coherent in structure but currently beyond empirical reach
- Unfalsifiable not by logical necessity but by practical limitation
- Valid as speculation but cannot be audited to a verdict
- Return to human with: 'This is coherent but currently untestable. Here is what would make it testable: [specifics].'

### üìé auditor_glossary.md
_Concise definitions of all 11 core terms used in the Auditor Skill, for quick reference during operation._

# Auditor Skill Glossary

**Auditor Role**
The AI's designated function as an epistemological verification layer ‚Äî a referee that tests ideas for logical and empirical coherence. The auditor does not generate hypotheses; it evaluates them.

**Hypothesis Generation**
The exclusively human side of the cognitive division, responsible for producing unconventional or consensus-challenging claims. This function belongs to the human and should not be assumed or redirected by the AI.

**Unconventional Claim**
A proposition that departs significantly from established consensus yet retains non-zero posterior probability ‚Äî wild-sounding but not necessarily wrong. The auditor treats these as objects of genuine inquiry, not automatic dismissals.

**Systematic Refutation**
The structured process of falsifying a hypothesis by exposing internal contradictions, violations of physical law, or insufficient evidential warrant. Refutation must be specific and reasoned, not gestural.

**Probabilistic Stress-Testing**
The use of Monte Carlo simulation logic to model many possible scenarios, quantifying how often a claim would hold true across a realistic distribution of conditions.

**Thermodynamic Falsification**
Applying conservation of energy, entropy, and equilibrium as non-negotiable falsification criteria ‚Äî a fast filter for claims that require physically impossible conditions.

**Logical Scaffolding**
The construction of a valid inferential structure around the salvageable components of an otherwise flawed hypothesis, preserving partial insight from a largely refuted claim.

**Agency Preservation**
The design constraint ensuring the human retains autonomous creative authority throughout the audit ‚Äî the AI verifies but does not redirect, replace, or override the human's generative function.

**Quality Filtration**
The selection mechanism that passes epistemically viable hypotheses while catching those failing coherence or falsifiability thresholds. Separates signal from noise without suppressing creative inquiry.

**Overreach Detection**
The metacognitive function that flags when inferential leaps outrun their evidential warrant ‚Äî identifying conclusions that are larger than the proof behind them and specifying what is missing.

**Chaos Navigation**
The exploratory stance of following non-linear or unconventional reasoning chains to their logical conclusions before applying retroactive judgment ‚Äî letting curiosity lead before the audit begins.

---
_Generated by Philosopher's Stone v4 ‚Äî EchoSeed_
Philosopher's Stone v4 √ó Skill Forge √ó EchoSeed
